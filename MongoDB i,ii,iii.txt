from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql import functions as F

def parseUserInput(line):
    fields = line.split('|')
    return Row(user_id=int(fields[0]), age=int(fields[1]), gender=fields[2], occupation=fields[3], zip=fields[4])

def parseRatingInput(line):
    fields = line.split('\t')
    return Row(user_id=int(fields[0]), movie_id=int(fields[1]), rating=int(fields[2]), timestamp=int(fields[3]))

def parseMovieInput(line):
    fields = line.split('|')
    return Row(movie_id=int(fields[0]), title=fields[1], genres=fields[5:])

if __name__ == "__main__":
    spark = SparkSession.builder.appName("MongoIntegration").getOrCreate()
    
    # Load and parse the users data
    user_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/azlin/u.user")
    users = user_lines.map(parseUserInput)
    usersDF = spark.createDataFrame(users)

    # Load and parse the ratings data
    rating_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/azlin/u.data")
    ratings = rating_lines.map(parseRatingInput)
    ratingsDF = spark.createDataFrame(ratings)

    # Load and parse the movies data
    movie_lines = spark.sparkContext.textFile("hdfs:///user/maria_dev/azlin/u.item")
    movies = movie_lines.map(parseMovieInput)
    moviesDF = spark.createDataFrame(movies)
    
    # Write DataFrames into MongoDB
    usersDF.write.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.users").mode('append').save()
    ratingsDF.write.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.ratings").mode('append').save()
    moviesDF.write.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.movies").mode('append').save()

    # Read DataFrames back from MongoDB
    usersDF = spark.read.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.users").load()
    ratingsDF = spark.read.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.ratings").load()
    moviesDF = spark.read.format("com.mongodb.spark.sql.DefaultSource")\
        .option("uri", "mongodb://127.0.0.1/movielens.movies").load()
    
    # Create Temp Views for SQL queries
    usersDF.createOrReplaceTempView("users")
    ratingsDF.createOrReplaceTempView("ratings")
    moviesDF.createOrReplaceTempView("movies")

    # Question (i): Calculate the average rating for each movie
    avg_ratings = spark.sql("""
        SELECT movie_id, AVG(rating) as avg_rating
        FROM ratings
        GROUP BY movie_id
    """)
    avg_ratings.show(10)

    # Question (ii): Identify the top ten movies with the highest average ratings
    top_ten_movies = avg_ratings.join(moviesDF, "movie_id")\
        .select("title", "avg_rating")\
        .orderBy(F.desc("avg_rating"))\
        .limit(10)
    top_ten_movies.show()

    # Question (iii): Find the users who have rated at least 50 movies and identify their favorite movie genres
    users_50_ratings = spark.sql("""
        SELECT user_id, COUNT(movie_id) as movie_count
        FROM ratings
        GROUP BY user_id
        HAVING movie_count >= 50
    """)
    users_50_ratings.createOrReplaceTempView("users_50_ratings")

    favorite_genres = spark.sql("""
        SELECT u.user_id, m.genres, COUNT(m.movie_id) as genre_count
        FROM users_50_ratings u
        JOIN ratings r ON u.user_id = r.user_id
        JOIN movies m ON r.movie_id = m.movie_id
        GROUP BY u.user_id, m.genres
        ORDER BY u.user_id, genre_count DESC
    """)
    favorite_genres.show(10)

    # Question (iv): Find all the users with age that is less than 20 years old
    users_below_20 = spark.sql("""
        SELECT * 
        FROM users 
        WHERE age < 20 
        LIMIT 10
    """)
    users_below_20.show()

    # Question (v): Find all the users who have the occupation "scientist" and their age is between 30 and 40 years old
    scientists_30_40 = spark.sql("""
        SELECT * 
        FROM users 
        WHERE occupation = 'scientist' AND age BETWEEN 30 AND 40 
        LIMIT 10
    """)
    scientists_30_40.show()

    # Stop the session
    spark.stop()
